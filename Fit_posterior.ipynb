{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bc4ecc",
   "metadata": {},
   "source": [
    "In this tutorial, we show how to use the fSBI method proposed in the companion paper.\n",
    "We will be performing an additional fSBI round:\n",
    "- we start from the final posterior in the paper (the \"plausible candidate rules\", \\pi_3, either MLP or polynomial).\n",
    "- we will generate additional rules with more specific excitatory rates (between 5 and 10Hz). The initial filtering done in the paper includes rules with rates between 1 and 50Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789acd2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T15:59:24.057282Z",
     "start_time": "2022-10-12T15:59:22.622463Z"
    }
   },
   "outputs": [],
   "source": [
    "from synapsbi.density_estimator import MakePosterior\n",
    "from synapsbi.utils import get_density_estim_data, resample_old_data, load_and_merge, apply_n_conditions\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import argparse\n",
    "import yaml\n",
    "import pickle\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60436cb6",
   "metadata": {},
   "source": [
    "#### 1/ Choose samples from the polynomial search space (See Fig 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8c34726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example additional fSBI round: we start from the final posterior in the paper (\"plausible rules\", pi3)\n",
    "# and generate additional rules with more specific excitatory rates (between 5 and 10Hz)\n",
    "round_name = \"pi3_r5to10Hz\"\n",
    "\n",
    "# samples generated from pi3, simulated in the paper with all metrics computed\n",
    "data_path = \"data_synapsesbi/bg_IF_EEEIIEII_6pPol/\"\n",
    "# name: bg: stability task (background inputs), IF: integrate and fir neuron model in Auryn,EE EI IE II recurrent synapses plastic, 6pPol: polynomial parmeterization with 6 params. \n",
    "\n",
    "# where to store the posteriors\n",
    "runs_path = \"runs_synapsesbi/bg_IF_EEEIIEII_6pPol/\"\n",
    "\n",
    "# simulation parameters\n",
    "path_to_sim_config = \"tasks_configs/bg_IF_EEEIIEII_6pPol.yaml\"\n",
    "with open(path_to_sim_config, \"r\") as f:\n",
    "    sim_params = yaml.load(f, Loader=yaml.Loader)\n",
    "    \n",
    "# the bounds for the plasticity parameters\n",
    "# time constants are between 10ms and 100ms, other params between -2 and 2\n",
    "lower_lim=torch.tensor([0.01, 0.01, -2., -2., -2., -2.,\n",
    "            0.01, 0.01, -2., -2., -2., -2.,\n",
    "            0.01, 0.01, -2., -2., -2., -2.,\n",
    "            0.01, 0.01, -2., -2., -2., -2.])\n",
    "upper_lim=torch.tensor([.1, .1, 2., 2., 2., 2.,\n",
    "        .1, .1, 2., 2., 2., 2.,\n",
    "        .1, .1, 2., 2., 2., 2.,\n",
    "        .1, .1, 2., 2., 2., 2.])\n",
    "\n",
    "# which metrics to train the posterior on\n",
    "# fitting a posterior on too many metrics at the same time (especially similar metrics) generates worse posteriors\n",
    "metrics = [\"rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "711708ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved 354300/354300 simulations\n",
      "24262/354300 samples kept for training\n"
     ]
    }
   ],
   "source": [
    "## load all the rules simulated in the paper (pi0 -> pi3).\n",
    "dataset_aux = load_and_merge(data_path, (\"bg_IF_EEEIIEII_6pPol_all.npy\",))\n",
    "\n",
    "# only keep the rules with exc rates between 3 and 15Hz for the training ([5,10] + some leeway)\n",
    "cond_r = (\"rate\", 3, 15)\n",
    "\n",
    "# the other conditions on plausibility from the paper\n",
    "cond_cv = (\"cv_isi\", 0.7, 1000)\n",
    "cond_sf = (\"spatial_Fano\", 0.5, 2.5)\n",
    "cond_tf = (\"temporal_Fano\", 0.5, 2.5)\n",
    "cond_ac = (\"auto_cov\", 0, 0.1)\n",
    "cond_fft = (\"fft\", 0, 1)\n",
    "cond_wb = (\"w_blow\", 0, 0.1)\n",
    "cond_srt = (\"std_rate_temporal\", 0, 0.5)\n",
    "cond_srs = (\"std_rate_spatial\", 0, 5)\n",
    "cond_scv = (\"std_cv\", 0, 0.2)\n",
    "cond_wc = (\"w_creep\", 0, 0.05)\n",
    "cond_ri = (\"rate_i\", 1, 50)\n",
    "cond_weef =(\"weef\", 0 ,0.5)\n",
    "cond_weif =(\"weif\", 0 ,0.5)\n",
    "cond_wief =(\"wief\", 0 ,5)\n",
    "cond_wiif =(\"wiif\", 0 ,5)\n",
    "\n",
    "condition = apply_n_conditions(dataset_aux, (cond_r,cond_ri,\n",
    "            cond_wb,cond_wc,cond_weef,cond_weif, cond_wief, cond_wiif,\n",
    "            cond_ac,cond_cv,cond_fft,cond_srt,cond_srs,cond_sf,cond_tf))\n",
    "\n",
    "dataset = dataset_aux[condition]\n",
    "print(str(np.sum(condition)) + \"/\" + str(len(condition)), \"samples kept for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a60cfb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1 bis/ Choose samples from the MLP search space (See Fig 4) \n",
    "\n",
    "Choose one between MLP or polynomial rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19c0c863",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "round_name = \"pi3_r5to10Hz\"\n",
    "data_path = \"data_synapsesbi/bg_CVAIF_EEIE_T4wvceciMLP/\"\n",
    "runs_path = \"runs_synapsesbi/bg_CVAIF_EEIE_T4wvceciMLP/\"\n",
    "path_to_sim_config = \"./tasks_configs/bg_CVAIF_EEIE_T4wvceciMLP.yaml\"\n",
    "with open(path_to_sim_config, \"r\") as f:\n",
    "    sim_params = yaml.load(f, Loader=yaml.Loader)\n",
    "lower_lim=torch.tensor([0., 0., -1., -1., -1., -1., #etaEE, etaIE, WpreEE, WpostEE, WpreIE, WpostIE\n",
    "            -1., -1., -1., -1., -1., -1.,\n",
    "            -1., -1., -1., -1., -1., -1.,\n",
    "            -1., -1., -1., -1.])\n",
    "upper_lim=torch.tensor([1., 1., 1., 1., 1., 1., #etaEE, etaIE, WpreEE, WpostEE, WpreIE, WpostIE\n",
    "            1., 1., 1., 1., 1., 1.,\n",
    "            1., 1., 1., 1., 1., 1.,\n",
    "            1., 1., 1., 1.])\n",
    "\n",
    "metrics = [\"rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb2e29eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved 328990/328990 simulations\n",
      "24391/354300 samples kept for training\n"
     ]
    }
   ],
   "source": [
    "## Choose which samples to use for the fit\n",
    "dataset = load_and_merge(data_path,\n",
    "             (\"bg_CVAIF_EEIE_T4wvceciMLP_all.npy\",))\n",
    "\n",
    "# only keep the rules with exc rates between 3 and 15Hz for the training ([5,10] + some leeway)\n",
    "cond_r = (\"rate\", 3, 15)\n",
    "\n",
    "# the other conditions on plausibility from the paper\n",
    "cond_cv = (\"cv_isi\", 0.7, 1000)\n",
    "cond_sf = (\"spatial_Fano\", 0.5, 2.5)\n",
    "cond_tf = (\"temporal_Fano\", 0.5, 2.5)\n",
    "cond_ac = (\"auto_cov\", 0, 0.1)\n",
    "cond_fft = (\"fft\", 0, 1)\n",
    "cond_wb = (\"w_blow\", 0, 0.1)\n",
    "cond_srt = (\"std_rate_temporal\", 0, 0.5)\n",
    "cond_srs = (\"std_rate_spatial\", 0, 5)\n",
    "cond_scv = (\"std_cv\", 0, 0.2)\n",
    "cond_wc = (\"w_creep\", 0, 0.05)\n",
    "cond_ri = (\"rate_i\", 1, 50)\n",
    "cond_weef =(\"weef\", 0 ,0.5)\n",
    "cond_wief =(\"wief\", 0 ,5)\n",
    "\n",
    "condition = apply_n_conditions(dataset_aux, (cond_r,cond_ri,\n",
    "            cond_wb,cond_wc,cond_weef,cond_wief,\n",
    "            cond_ac,cond_cv,cond_fft,cond_srt,cond_srs,cond_sf,cond_tf))\n",
    "\n",
    "dataset = dataset_aux[condition]\n",
    "print(str(np.sum(condition)) + \"/\" + str(len(condition)), \"samples kept for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c112094",
   "metadata": {},
   "source": [
    "#### 2/ Fit a posterior with the sbi package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8021b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = {'low':lower_lim,\n",
    "          'high':upper_lim}\n",
    "prior = torch.distributions.Uniform(low=lower_lim, high=upper_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6694cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the [theta, xs] for training\n",
    "thetas = torch.tensor(dataset['theta'][:,:-1], dtype=torch.float32) #remove nuisance parameter from training (input rate)\n",
    "xs = torch.tensor([[dataset[i][j] for i in metrics] for j in range(len(dataset))], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d73e6cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T16:00:20.023663Z",
     "start_time": "2022-10-12T16:00:00.071564Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior will be put to none for now anyway. we do rejection sampling after the fitting instead\n",
      " Neural network successfully converged after 145 epochs.1659.6950862407684\n"
     ]
    }
   ],
   "source": [
    "# train and save the posterior\n",
    "# this can take time (~1h) depending on your hardware.\n",
    "tic = time()\n",
    "mk_post = MakePosterior(**sim_params[\"prior_params\"])\n",
    "\n",
    "mk_post.get_ensemble_posterior(\n",
    "    thetas,\n",
    "    xs,\n",
    "    save_path=runs_path + \"posterior_\" + round_name + \".pkl\")\n",
    "toc = time() - tic\n",
    "print(toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a28901",
   "metadata": {},
   "source": [
    "Congratulations, you now have a posterior you can sample new rules from!     \n",
    "\n",
    "Head to the Sample_from_posterior jupyter notebook to do that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "61711b8cf7d2775f177b340d6eca0bb8d2b4f06be813726212ddbc6469b2ca7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
